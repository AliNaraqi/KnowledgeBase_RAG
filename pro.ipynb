{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612e251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "750bb182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path='api.env',override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12592f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key=os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ali-onboarding-api-key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c690d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3464b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ade78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "\n",
    "employees = glob.glob(\"Knowledge-base/Employees/*\")\n",
    "\n",
    "for employee in employees:\n",
    "    name = employee.split(' ')[-1][:-3]\n",
    "    doc = \"\"\n",
    "    with open(employee, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f6aca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985  \\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \\n- **Location**: San Francisco, California  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.  \\n\\n- **2010 - 2013**: Business Analyst at Edge Analytics  \\n  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\\n\\n## Annual Performance History\\n- **2015**: **Exceeds Expectations**  \\n  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \\n\\n- **2016**: **Meets Expectations**  \\n  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \\n\\n- **2017**: **Developing**  \\n  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \\n\\n- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\\n\\n## Compensation History\\n- **2015**: $150,000 base salary + Significant equity stake  \\n- **2016**: $160,000 base salary + Equity increase  \\n- **2017**: $150,000 base salary + Decrease in bonus due to performance  \\n- **2018**: $180,000 base salary + performance bonus of $30,000  \\n- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \\n- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \\n- **2021**: $200,000 base salary + performance bonus of $50,000  \\n- **2022**: $210,000 base salary + retention bonus  \\n- **2023**: $225,000 base salary + $75,000 performance bonus  \\n\\n## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context[\"Lancaster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d215cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = glob.glob(\"Knowledge-base/Products/*\")\n",
    "\n",
    "for product in products:\n",
    "    name = product.split(os.sep)[-1][:-3]\n",
    "    doc = \"\"\n",
    "    with open(product, \"r\", encoding=\"utf-8\") as f:\n",
    "        doc = f.read()\n",
    "    context[name]=doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f533ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Chen', 'Spencer', 'Tran', 'Blake', 'Lancaster', 'Thompson', 'Greene', 'Thomson', 'Trenton', 'Harper', 'Bishop', 'Carter', 'Rellm', 'Markellm', 'Homellm', 'Carllm'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fadf0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an expert in answering accurate questions about Insurellm, the Insurance Tech company. Give brief, accurate answers. If you don't know the answer, say so. Do not make anything up if you haven't been provided with relevant context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36dd061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context = []\n",
    "    for context_title, context_details in context.items():\n",
    "        if context_title.lower() in message.lower():\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "434a649e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"# Avery Lancaster\\n\\n## Summary\\n- **Date of Birth**: March 15, 1985  \\n- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \\n- **Location**: San Francisco, California  \\n\\n## Insurellm Career Progression\\n- **2015 - Present**: Co-Founder & CEO  \\n  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \\n\\n- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \\n  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.  \\n\\n- **2010 - 2013**: Business Analyst at Edge Analytics  \\n  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\\n\\n## Annual Performance History\\n- **2015**: **Exceeds Expectations**  \\n  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \\n\\n- **2016**: **Meets Expectations**  \\n  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \\n\\n- **2017**: **Developing**  \\n  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \\n\\n- **2018**: **Exceeds Expectations**  \\n  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \\n\\n- **2019**: **Meets Expectations**  \\n  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \\n\\n- **2020**: **Below Expectations**  \\n  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \\n\\n- **2021**: **Exceptional**  \\n  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \\n\\n- **2022**: **Satisfactory**  \\n  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \\n\\n- **2023**: **Exceeds Expectations**  \\n  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\\n\\n## Compensation History\\n- **2015**: $150,000 base salary + Significant equity stake  \\n- **2016**: $160,000 base salary + Equity increase  \\n- **2017**: $150,000 base salary + Decrease in bonus due to performance  \\n- **2018**: $180,000 base salary + performance bonus of $30,000  \\n- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \\n- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \\n- **2021**: $200,000 base salary + performance bonus of $50,000  \\n- **2022**: $210,000 base salary + retention bonus  \\n- **2023**: $225,000 base salary + $75,000 performance bonus  \\n\\n## Other HR Notes\\n- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \\n- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \\n- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\\n- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \\n\\nAvery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"Who is lancaster?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2400464d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Product Summary\\n\\n# Carllm\\n\\n## Summary\\n\\nCarllm is an innovative auto insurance product developed by Insurellm, designed to streamline the way insurance companies offer coverage to their customers. Powered by cutting-edge artificial intelligence, Carllm utilizes advanced algorithms to deliver personalized auto insurance solutions, ensuring optimal coverage while minimizing costs. With a robust infrastructure that supports both B2B and B2C customers, Carllm redefines the auto insurance landscape and empowers insurance providers to enhance customer satisfaction and retention.\\n\\n## Features\\n\\n- **AI-Powered Risk Assessment**: Carllm leverages artificial intelligence to analyze driver behavior, vehicle conditions, and historical claims data. This enables insurers to make informed decisions and set competitive premiums that reflect true risk profiles.\\n\\n- **Instant Quoting**: With Carllm, insurance companies can offer near-instant quotes to customers, enhancing the customer experience. The AI engine processes data in real-time, drastically reducing the time it takes to generate quotes.\\n\\n- **Customizable Coverage Plans**: Carllm allows insurers to create flexible and tailored insurance packages based on individual customer needs. This customization improves customer engagement and retention.\\n\\n- **Fraud Detection**: The product incorporates advanced analytics to identify potentially fraudulent claims, significantly reducing the risk of losses for insurance providers.\\n\\n- **Customer Insights Dashboard**: Carllm provides insurers with a powerful dashboard that offers deep insights into customer behavior, claims patterns, and market trends, enabling informed decision-making and strategic planning.\\n\\n- **Mobile Integration**: Carllm is designed to work seamlessly with mobile applications, providing both insurers and end-users access to policy management and claims reporting on the go.\\n\\n- **Automated Customer Support**: Leveraging AI chatbots, Carllm offers 24/7 customer support, helping to resolve inquiries quickly and efficiently, thus improving customer satisfaction.\\n\\n## Pricing\\n\\nCarllm is offered under a subscription-based pricing model tailored to meet the needs of insurance companies of all sizes. Our pricing tiers are designed to provide maximum flexibility and value:\\n\\n- **Basic Tier**: $1,000/month\\n  - Ideal for small insurance firms.\\n  - Access to core features and standard reporting.\\n\\n- **Professional Tier**: $2,500/month\\n  - For medium-sized companies.\\n  - All Basic Tier features plus advanced analytics and fraud detection.\\n\\n- **Enterprise Tier**: $5,000/month\\n  - Customized solutions for large insurance firms.\\n  - Comprehensive support, full feature access, and integration with existing systems.\\n\\nContact our sales team for a personalized quote and discover how Carllm can transform your auto insurance offerings!\\n\\n## 2025-2026 Roadmap\\n\\nIn our commitment to continuous improvement and innovation, Insurellm has outlined the following roadmap for Carllm:\\n\\n### Q1 2025: Launch Feature Enhancements\\n- **Expanded data integrations** for better risk assessment.\\n- **Enhanced fraud detection algorithms** to reduce losses.\\n\\n### Q2 2025: Customer Experience Improvements\\n- Launch of a new **mobile app** for end-users.\\n- Introduction of **telematics-based pricing** to provide even more tailored coverage options.\\n\\n### Q3 2025: Global Expansion\\n- Begin pilot programs for international insurance markets.\\n- Collaborate with local insurers to offer compliant, localized versions of Carllm.\\n\\n### Q4 2025: AI and Machine Learning Upgrades\\n- Implement next-gen machine learning models for predictive analysis.\\n- Roll out customer insights dashboard updates based on user feedback.\\n\\n### 2026: Scaling and Partnerships\\n- Increase partnerships with automakers for integrated insurance solutions.\\n- Enhance the **AI customer support system** to include multi-language support.\\n\\nCarllm is not just an auto insurance product; it is a transformative tool for the insurance industry. Join us on this exciting journey as we redefine the future of auto insurance with technology and customer-centric solutions.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_relevant_context(\"Who is Avery and what is carllm?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6932dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if relevant_context:\n",
    "        message += \"\\n\\nThe following additional context might be relevant in answering this question:\\n\\n\"\n",
    "        for relevant in relevant_context:\n",
    "            message += relevant + \"\\n\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a9df952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Alex Lancaster?\n",
      "\n",
      "The following additional context might be relevant in answering this question:\n",
      "\n",
      "# Avery Lancaster\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: March 15, 1985  \n",
      "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
      "- **Location**: San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2015 - Present**: Co-Founder & CEO  \n",
      "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
      "\n",
      "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
      "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.  \n",
      "\n",
      "- **2010 - 2013**: Business Analyst at Edge Analytics  \n",
      "  Prior to joining Innovate, Avery worked as a Business Analyst, focusing on market trends and consumer preferences in the insurance space. This position laid the groundwork for Avery’s future entrepreneurial endeavors.\n",
      "\n",
      "## Annual Performance History\n",
      "- **2015**: **Exceeds Expectations**  \n",
      "  Avery’s leadership during Insurellm's foundational year led to successful product launches and securing initial funding.  \n",
      "\n",
      "- **2016**: **Meets Expectations**  \n",
      "  Growth continued, though challenges arose in operational efficiency that required Avery's attention.  \n",
      "\n",
      "- **2017**: **Developing**  \n",
      "  Market competition intensified, and monthly sales metrics were below targets. Avery implemented new strategies which required a steep learning curve.  \n",
      "\n",
      "- **2018**: **Exceeds Expectations**  \n",
      "  Under Avery’s pivoted vision, Insurellm launched two new successful products that significantly increased market share.  \n",
      "\n",
      "- **2019**: **Meets Expectations**  \n",
      "  Steady growth, however, some team tensions led to a minor drop in employee morale. Avery recognized the need to enhance company culture.  \n",
      "\n",
      "- **2020**: **Below Expectations**  \n",
      "  The COVID-19 pandemic posed unforeseen operational difficulties. Avery faced criticism for delayed strategy shifts, although efforts were eventually made to stabilize the company.  \n",
      "\n",
      "- **2021**: **Exceptional**  \n",
      "  Avery's decisive transition to remote work and rapid adoption of digital tools led to record-high customer satisfaction levels and increased sales.  \n",
      "\n",
      "- **2022**: **Satisfactory**  \n",
      "  Avery focused on rebuilding team dynamics and addressing employee concerns, leading to overall improvement despite a saturated market.  \n",
      "\n",
      "- **2023**: **Exceeds Expectations**  \n",
      "  Market leadership was regained with innovative approaches to personalized insurance solutions. Avery is now recognized in industry publications as a leading voice in Insurance Tech innovation.\n",
      "\n",
      "## Compensation History\n",
      "- **2015**: $150,000 base salary + Significant equity stake  \n",
      "- **2016**: $160,000 base salary + Equity increase  \n",
      "- **2017**: $150,000 base salary + Decrease in bonus due to performance  \n",
      "- **2018**: $180,000 base salary + performance bonus of $30,000  \n",
      "- **2019**: $185,000 base salary + market adjustment + $5,000 bonus  \n",
      "- **2020**: $170,000 base salary (temporary reduction due to COVID-19)  \n",
      "- **2021**: $200,000 base salary + performance bonus of $50,000  \n",
      "- **2022**: $210,000 base salary + retention bonus  \n",
      "- **2023**: $225,000 base salary + $75,000 performance bonus  \n",
      "\n",
      "## Other HR Notes\n",
      "- **Professional Development**: Avery has actively participated in leadership training programs and industry conferences, representing Insurellm and fostering partnerships.  \n",
      "- **Diversity & Inclusion Initiatives**: Avery has championed a commitment to diversity in hiring practices, seeing visible improvements in team representation since 2021.  \n",
      "- **Work-Life Balance**: Feedback revealed concerns regarding work-life balance, which Avery has approached by implementing flexible working conditions and ensuring regular check-ins with the team.\n",
      "- **Community Engagement**: Avery led community outreach efforts, focusing on financial literacy programs, particularly aimed at underserved populations, improving Insurellm's corporate social responsibility image.  \n",
      "\n",
      "Avery Lancaster has demonstrated resilience and adaptability throughout her career at Insurellm, positioning the company as a key player in the insurance technology landscape.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(add_context(\"Who is Alex Lancaster?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2fa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history\n",
    "    message = add_context(message)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = client.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6f9f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "888fbdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing chat function...\n",
      "Response: \n",
      "✅ Chat function is working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the chat function to ensure it works\n",
    "test_history = []\n",
    "test_message = \"Who is Avery Lancaster?\"\n",
    "\n",
    "print(\"Testing chat function...\")\n",
    "try:\n",
    "    for response in chat(test_message, test_history):\n",
    "        print(f\"Response: {response}\")\n",
    "        break  # Just get the first response for testing\n",
    "    print(\"✅ Chat function is working correctly!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in chat function: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "671f52be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039a2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob.glob(\"Knowledge-base/\")\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    for doc in folder_docs:\n",
    "        doc.metadata[\"doc_type\"] = doc_type\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37fad1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32bca7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1088, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a095fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6dd8ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Knowledge-base/Contracts/Contract with Apex Reinsurance for Rellm.md', 'doc_type': ''}, page_content='# Contract with Apex Reinsurance for Rellm: AI-Powered Enterprise Reinsurance Solution\\n\\n## Terms\\n\\n1. **Parties Involved**: This contract (“Agreement”) is entered into between Insurellm, Inc. (“Provider”) and Apex Reinsurance (“Client”) on this [Date].\\n\\n2. **Scope of Services**: Provider agrees to deliver the Rellm solution, which includes AI-driven analytics, seamless integrations, risk assessment modules, customizable dashboards, regulatory compliance tools, and client and broker portals as described in the product summary.\\n\\n3. **Payment Terms**: Client shall pay the Provider the sum of $10,000 per month for the duration of this agreement. Payments are due on the first day of each month and will be processed via electronic funds transfer.\\n\\n4. **Contract Duration**: This Agreement shall commence on [Start Date] and shall remain in effect for a period of twelve (12) months unless terminated earlier in accordance with the terms set forth herein.\\n\\n## Renewal')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa21364c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document types found: \n"
     ]
    }
   ],
   "source": [
    "doc_types = set(chunk.metadata['doc_type'] for chunk in chunks)\n",
    "print(f\"Document types found: {', '.join(doc_types)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "376c53d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='## Support\n",
      "\n",
      "1. **Customer Support**: Velocity Auto Solutions will have access to Insurellm’s customer support team via email or chatbot, available 24/7.  \n",
      "2. **Technical Maintenance**: Regular maintenance and updates to the Carllm platform will be conducted by Insurellm, with any downtime communicated in advance.  \n",
      "3. **Training & Resources**: Initial training sessions will be provided for Velocity Auto Solutions’ staff to ensure effective use of the Carllm suite. Regular resources and documentation will be made available online.\n",
      "\n",
      "---\n",
      "\n",
      "**Accepted and Agreed:**  \n",
      "**For Velocity Auto Solutions**  \n",
      "Signature: _____________________  \n",
      "Name: John Doe  \n",
      "Title: CEO  \n",
      "Date: _____________________  \n",
      "\n",
      "**For Insurellm**  \n",
      "Signature: _____________________  \n",
      "Name: Jane Smith  \n",
      "Title: VP of Sales  \n",
      "Date: _____________________' metadata={'source': 'Knowledge-base/Contracts/Contract with Velocity Auto Solutions for Carllm.md', 'doc_type': ''}\n",
      "_________\n",
      "page_content='3. **Regular Updates:** Insurellm will offer ongoing updates and enhancements to the Homellm platform, including new features and security improvements.\n",
      "\n",
      "4. **Feedback Implementation:** Insurellm will actively solicit feedback from GreenValley Insurance to ensure Homellm continues to meet their evolving needs.\n",
      "\n",
      "---\n",
      "\n",
      "**Signatures:**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: CEO  \n",
      "**Insurellm, Inc.**\n",
      "\n",
      "_________________________________  \n",
      "**[Name]**  \n",
      "**Title**: COO  \n",
      "**GreenValley Insurance, LLC**  \n",
      "\n",
      "---\n",
      "\n",
      "This agreement represents the complete understanding of both parties regarding the use of the Homellm product and supersedes any prior agreements or communications.' metadata={'source': 'Knowledge-base/Contracts/Contract with GreenValley Insurance for Homellm.md', 'doc_type': ''}\n",
      "_________\n",
      "page_content='# Avery Lancaster\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: March 15, 1985  \n",
      "- **Job Title**: Co-Founder & Chief Executive Officer (CEO)  \n",
      "- **Location**: San Francisco, California  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2015 - Present**: Co-Founder & CEO  \n",
      "  Avery Lancaster co-founded Insurellm in 2015 and has since guided the company to its current position as a leading Insurance Tech provider. Avery is known for her innovative leadership strategies and risk management expertise that have catapulted the company into the mainstream insurance market.  \n",
      "\n",
      "- **2013 - 2015**: Senior Product Manager at Innovate Insurance Solutions  \n",
      "  Before launching Insurellm, Avery was a leading Senior Product Manager at Innovate Insurance Solutions, where she developed groundbreaking insurance products aimed at the tech sector.' metadata={'source': 'Knowledge-base/Employees/Avery Lancaster.md', 'doc_type': ''}\n",
      "_________\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    if 'CEO' in chunk.page_content:\n",
    "        print(chunk)\n",
    "        print(\"_________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7030781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea785ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simple vector store...\n",
      "Creating embeddings for documents...\n",
      "✅ Created embeddings for 119 documents\n",
      "✅ Vector store created with 119 documents\n",
      "Vector store type: <class '__main__.SimpleVectorStore'>\n"
     ]
    }
   ],
   "source": [
    "class SimpleVectorStore:\n",
    "    def __init__(self, documents, embeddings_model):\n",
    "        self.documents = documents\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.embeddings = None\n",
    "        self._build_embeddings()\n",
    "    \n",
    "    def _build_embeddings(self):\n",
    "        \"\"\"Create embeddings for all documents\"\"\"\n",
    "        print(\"Creating embeddings for documents...\")\n",
    "        texts = [doc.page_content for doc in self.documents]\n",
    "        self.embeddings = self.embeddings_model.embed_documents(texts)\n",
    "        print(f\"✅ Created embeddings for {len(self.documents)} documents\")\n",
    "    \n",
    "    def similarity_search(self, query, k=3):\n",
    "        \"\"\"Search for similar documents using cosine similarity\"\"\"\n",
    "        # Get query embedding\n",
    "        query_embedding = self.embeddings_model.embed_query(query)\n",
    "        query_embedding = np.array(query_embedding).reshape(1, -1)\n",
    "        \n",
    "        # Calculate cosine similarities\n",
    "        similarities = cosine_similarity(query_embedding, self.embeddings)[0]\n",
    "        \n",
    "        # Get top k most similar documents\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                'document': self.documents[idx],\n",
    "                'similarity': similarities[idx]\n",
    "            })\n",
    "        \n",
    "        return [result['document'] for result in results]\n",
    "\n",
    "\n",
    "print(\"Creating simple vector store...\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "vectorstore = SimpleVectorStore(chunks, embeddings)\n",
    "\n",
    "print(f\"✅ Vector store created with {len(chunks)} documents\")\n",
    "print(f\"Vector store type: {type(vectorstore)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5e44338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 relevant documents for query: 'Who is Olivevr Spencer and what is her role?'\n",
      "\n",
      "--- Document 1 ---\n",
      "Source: Knowledge-base/Employees/Oliver Spencer.md\n",
      "Content preview: # HR Record\n",
      "\n",
      "# Oliver Spencer\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth**: May 14, 1990  \n",
      "- **Job Title**: Backend Software Engineer  \n",
      "- **Location**: Austin, Texas  \n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **March 20...\n",
      "\n",
      "--- Document 2 ---\n",
      "Source: Knowledge-base/Employees/Samantha Greene.md\n",
      "Content preview: # Samantha Greene\n",
      "\n",
      "## Summary\n",
      "- **Date of Birth:** October 14, 1990\n",
      "- **Job Title:** HR Generalist\n",
      "- **Location:** Denver, Colorado\n",
      "\n",
      "## Insurellm Career Progression\n",
      "- **2020** - Joined Insurellm as a ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to search for relevant documents\n",
    "def search_documents(query, k=3):\n",
    "    \"\"\"\n",
    "    Search for relevant documents using simple vector store\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query\n",
    "        k (int): Number of documents to return\n",
    "    \n",
    "    Returns:\n",
    "        List of relevant documents\n",
    "    \"\"\"\n",
    "    # Perform similarity search\n",
    "    docs = vectorstore.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"Found {len(docs)} relevant documents for query: '{query}'\")\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"\\n--- Document {i} ---\")\n",
    "        print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "        print(f\"Content preview: {doc.page_content[:200]}...\")\n",
    "    \n",
    "    return docs\n",
    "\n",
    "# Test the search function\n",
    "test_query = \"Who is Olivevr Spencer and what is her role?\"\n",
    "relevant_docs = search_documents(test_query, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab3197fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing enhanced chat function...\n",
      "Question: What products does Insurellm offer?\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "# Enhanced chat function using simple vector store\n",
    "def enhanced_chat(message, history):\n",
    "    \"\"\"\n",
    "    Enhanced chat function that uses simple vector store for better context retrieval\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    relevant_docs = vectorstore.similarity_search(message, k=3)\n",
    "    \n",
    "    # Build context from relevant documents\n",
    "    context = \"\"\n",
    "    for i, doc in enumerate(relevant_docs, 1):\n",
    "        context += f\"Document {i}:\\n{doc.page_content}\\n\\n\"\n",
    "    \n",
    "    # Create messages with system prompt and context\n",
    "    messages = [{\"role\": \"system\", \"content\": f\"{system_message}\\n\\nRelevant context:\\n{context}\"}] + history\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # Get response from OpenAI\n",
    "    stream = client.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response\n",
    "\n",
    "# Test the enhanced chat function\n",
    "print(\"Testing enhanced chat function...\")\n",
    "test_history = []\n",
    "test_message = \"What products does Insurellm offer?\"\n",
    "\n",
    "print(f\"Question: {test_message}\")\n",
    "print(\"Answer:\")\n",
    "for response in enhanced_chat(test_message, test_history):\n",
    "    print(response, end=\"\")\n",
    "    break  # Just get the first response for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa0ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating enhanced RAG interface...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Creating enhanced RAG interface...\")\n",
    "\n",
    "enhanced_view = gr.ChatInterface(\n",
    "    enhanced_chat, \n",
    "    title=\"Insurellm RAG Assistant (Enhanced with Vector Search)\",\n",
    "    description=\"Ask questions about Insurellm employees, products, and contracts. Powered by semantic vector search.\",\n",
    "    type=\"messages\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79766bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector store saved to insurellm_vectorstore.pkl\n"
     ]
    }
   ],
   "source": [
    "# Simple persistence for vector store\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_vectorstore(vectorstore, path=\"simple_vectorstore.pkl\"):\n",
    "    \"\"\"Save simple vector store to disk\"\"\"\n",
    "    try:\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'documents': vectorstore.documents,\n",
    "                'embeddings': vectorstore.embeddings\n",
    "            }, f)\n",
    "        print(f\"✅ Vector store saved to {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving vector store: {e}\")\n",
    "\n",
    "def load_vectorstore(embeddings_model, path=\"simple_vectorstore.pkl\"):\n",
    "    \"\"\"Load simple vector store from disk\"\"\"\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            with open(path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "            vectorstore = SimpleVectorStore.__new__(SimpleVectorStore)\n",
    "            vectorstore.documents = data['documents']\n",
    "            vectorstore.embeddings = data['embeddings']\n",
    "            vectorstore.embeddings_model = embeddings_model\n",
    "            print(f\"✅ Vector store loaded from {path}\")\n",
    "            return vectorstore\n",
    "        else:\n",
    "            print(f\"❌ File {path} not found\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading vector store: {e}\")\n",
    "        return None\n",
    "\n",
    "# Save the current vector store\n",
    "save_vectorstore(vectorstore, \"insurellm_vectorstore.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ec60c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chromadb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings, ChatOpenAI\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_chroma/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"This is the langchain_chroma package.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mIt contains the Chroma class for handling various tasks.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_chroma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChroma\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/langchain_chroma/vectorstores.py:20\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterable, Sequence\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     TYPE_CHECKING,\n\u001b[1;32m     14\u001b[0m     Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     Union,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6506a60f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
